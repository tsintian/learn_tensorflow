{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset comprises elements that each have the same structure. An element contains one or more `tf.Tensor` objects, called **components**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n(5, 10)\n<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 5, 10]))\n",
    "print(dataset1.output_types)\n",
    "print(dataset1.output_shapes)\n",
    "print(dataset1.output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape([]), TensorShape([Dimension(100)]))\n(tf.float32, tf.int32)\n"
     ]
    }
   ],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random_uniform([4]),\n",
    "    tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
    "\n",
    "print(dataset2.output_shapes)\n",
    "print(dataset2.output_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often convinient to give names to each **component** of an element, for example if they represent different features of a training example.\n",
    "\n",
    "In addtion to tupples, you can use `collections.namedtuple` or a dictionary mapping strings to tensors to represent a single element of a `Dataset`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': TensorShape([]), 'b': TensorShape([Dimension(100)])}\n{'a': tf.float32, 'b': tf.int32}\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    {\n",
    "        \"a\": tf.random_uniform([4]),\n",
    "        \"b\": tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(dataset.output_shapes)\n",
    "print(dataset.output_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have built a `Dataset` to represent your input data, the next step is to \n",
    "create an `Iterator` to access elements from that dataset.\n",
    "\n",
    "The `tf.data` API currently supports the following iterations:\n",
    "* **one-shot**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **initializable** iterator requires you to run an explicit `iterator.initializer` operation before using it. In exchange for this inconvenience, it enables you to parameterize the definition of the dataset using one or more `tf.placeholder()` tensors that can be fed when you initialize the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n"
     ]
    }
   ],
   "source": [
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "\n",
    "dataset = tf.data.Dataset.range(max_value)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Initialize an iterator over a dataset with 10 elements.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={\n",
    "        max_value: 10\n",
    "    })\n",
    "    for i in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(value)\n",
    "        \n",
    "# Initialize the same iterator over a dataset with 5 elements.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={\n",
    "        max_value: 5\n",
    "    })\n",
    "    for i in range(5):\n",
    "        value = sess.run(next_element)\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
