{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:02:58.833776Z",
     "start_time": "2019-09-11T13:02:58.830910Z"
    }
   },
   "outputs": [],
   "source": [
    "import iris_data\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 采用预创建的Estimator\n",
    "\n",
    "1. 创建输入函数\n",
    "2. 定义特征列\n",
    "3. 实例化Estimator\n",
    "4. 训练、评估和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T12:57:41.461168Z",
     "start_time": "2019-09-11T12:57:41.453023Z"
    }
   },
   "outputs": [],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T11:52:37.637786Z",
     "start_time": "2019-09-11T11:52:37.633481Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    return dataset.shuffle(1000).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义特征列　\n",
    "\n",
    "特征列是一个对象，用于说明模型应该如何使用特征字典中的原始输入数据。在构建 Estimator 模型时，您会向其传递一个特征列的列表，其中包含您希望模型使用的每个特征。tf.feature_column 模块提供很多用于在模型中表示数据的选项。\n",
    "\n",
    "对于鸢尾花问题，4 个原始特征是数值，因此我们会构建一个特征列的列表，以告知 Estimator 模型将这 4 个特征都表示为 32 位浮点值。因此，创建特征列的代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:03:17.519122Z",
     "start_time": "2019-09-11T13:03:17.503569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fetch the data\n",
    "(train_x, train_y), (test_x, test_y) = iris_data.load_data()\n",
    "\n",
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:03:51.849608Z",
     "start_time": "2019-09-11T13:03:51.837445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例化Estimator\n",
    "\n",
    "鸢尾花问题是一个经典的分类问题。幸运的是，TensorFlow 提供了几个预创建的分类器 Estimator，其中包括：\n",
    "\n",
    "- tf.estimator.DNNClassifier：适用于执行多类别分类的深度模型。\n",
    "- tf.estimator.DNNLinearCombinedClassifier：适用于宽度和深度模型。\n",
    "- tf.estimator.LinearClassifier：适用于基于线性模型的分类器。\n",
    "\n",
    "对于鸢尾花问题，tf.estimator.DNNClassifier 似乎是最好的选择。我们将如下所示地实例化此 Estimator："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:08:03.687629Z",
     "start_time": "2019-09-11T13:08:03.683648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = my_feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units = [10, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes = 3,\n",
    "    model_dir = 'models/iris'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:09:10.332879Z",
     "start_time": "2019-09-11T13:09:08.035141Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 21:09:08.057539 139799877797696 deprecation.py:323] From /home/tianqin/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0911 21:09:08.087918 139799877797696 deprecation.py:506] From /home/tianqin/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0911 21:09:08.756662 139799877797696 deprecation.py:323] From /home/tianqin/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0911 21:09:08.862176 139799877797696 deprecation.py:506] From /home/tianqin/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0911 21:09:08.963606 139799877797696 deprecation.py:323] From /home/tianqin/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f256609d1d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "input_fn=lambda: train_input_fn(train_x, train_y,batch_size=100),\n",
    "steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:10:47.830411Z",
     "start_time": "2019-09-11T13:10:47.820984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/iris'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:12:49.335772Z",
     "start_time": "2019-09-11T13:12:49.330931Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:16:15.283779Z",
     "start_time": "2019-09-11T13:16:14.693655Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 21:16:15.029642 139799877797696 deprecation.py:323] From /home/tianqin/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tst set accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model \n",
    "eval_result = classifier.evaluate(\n",
    "input_fn=lambda: eval_input_fn(test_x, test_y, batch_size=100))\n",
    "\n",
    "print('Tst set accuracy: {accuracy:0.3f}'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:16:23.736315Z",
     "start_time": "2019-09-11T13:16:23.729126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.96666664,\n",
       " 'average_loss': 0.09045978,\n",
       " 'loss': 2.7137933,\n",
       " 'global_step': 200}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:35:19.427717Z",
     "start_time": "2019-09-11T13:35:19.423786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: iris_data.eval_input_fn(\n",
    "    predict_x, labels=None, batch_size=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T13:35:20.747189Z",
     "start_time": "2019-09-11T13:35:20.289580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction is \"Setosa\" (98.5%), expected \"Setosa\"\n",
      "\n",
      "Prediction is \"Versicolor\" (95.2%), expected \"Versicolor\"\n",
      "\n",
      "Prediction is \"Virginica\" (91.5%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(iris_data.SPECIES[class_id],\n",
    "                          100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
